{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27f8c50-ff9f-47ce-a527-47d491f447db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidankeogh/opt/anaconda3/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 59634 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import sparse\n",
    "import dask_ml\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(memory_limit='6GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cda645d-1f4b-44ad-9ab2-f2b0c41c9a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628841 70060\n"
     ]
    }
   ],
   "source": [
    "seed = 25\n",
    "train = dd.read_csv(\"train_baselines.csv\")\n",
    "val = dd.read_csv(\"val_baselines.csv\")\n",
    "print(len(train), len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3496349f-8ba4-4a02-966c-64b6d8053343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating indices\n",
      "Creating sparse matrix 1.2017412185668945\n",
      "Generating dot products 3.1728110313415527\n",
      "Raw similarities computed 10.153905153274536\n",
      "Similarities normalized! 25.031099319458008\n"
     ]
    }
   ],
   "source": [
    "class SimilarityScorer:\n",
    "    def __init__(self, interactions):\n",
    "        start = time.time()\n",
    "        print(\"Generating indices\")\n",
    "        user_codes, self.user_idx_to_id = pd.factorize(interactions.user_id.compute())\n",
    "        recipe_codes, self.recipe_idx_to_id = pd.factorize(interactions.recipe_id.compute())\n",
    "\n",
    "        self.user_id_to_idx = {user: idx for idx, user in enumerate(self.user_idx_to_id)}\n",
    "        self.recipe_id_to_idx = {recipe: idx for idx, recipe in enumerate(self.recipe_idx_to_id)}\n",
    "        \n",
    "        print(\"Creating sparse matrix\", time.time() - start)\n",
    "        s = sparse.COO(\n",
    "            [user_codes, recipe_codes],\n",
    "            interactions.dual_bayesian_avg_delta.compute(),\n",
    "            shape=(len(self.user_idx_to_id), len(self.recipe_idx_to_id)),\n",
    "            fill_value=0\n",
    "        )\n",
    "        self.sparse_mat = da.from_array(s, chunks=(5000, 5000))\n",
    "        print(\"Generating dot products\", time.time() - start)\n",
    "\n",
    "        dot_product_similarities = (self.sparse_mat @ self.sparse_mat.T).compute()\n",
    "        print(\"Raw similarities computed\", time.time() - start)\n",
    "        \n",
    "        dense_similarities = dot_product_similarities.todense()\n",
    "        sims_summed = dense_similarities.sum(axis=1) + 1e-20\n",
    "        self.similarities = dense_similarities / sims_summed.reshape(-1, 1)\n",
    "        self.sparse_mat = self.sparse_mat.compute()\n",
    "        print(\"Similarities normalized!\", time.time() - start)\n",
    "\n",
    "    def predict_topk_for_user(self, user_id, k):\n",
    "        user_idx = self.user_id_to_idx[user_id]\n",
    "        similarities_norm = self.similarities_normalized[user_idx]\n",
    "        recs = self.similarities[user_idx] @ self.sparse_mat\n",
    "        rec_values = recs.topk(k)\n",
    "        rec_idxs = recs.argtopk(k)\n",
    "        recs_ids = [self.recipe_idx_to_id[idx] for idx in rec_idxs]\n",
    "        return recs_ids, rec_values\n",
    "    \n",
    "    def predict_pair(self, user_id, recipe_id):\n",
    "        if recipe_id not in self.recipe_id_to_idx or user_id not in self.user_id_to_idx:\n",
    "            return 0\n",
    "        user_idx = self.user_id_to_idx[user_id]\n",
    "        recipe_idx = self.recipe_id_to_idx[recipe_id]\n",
    "        predicted_score = self.similarities[user_idx] @ self.sparse_mat[:, recipe_idx]\n",
    "        return predicted_score\n",
    "\n",
    "scorer = SimilarityScorer(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd5b63d5-0f89-4406-9869-1e5466980b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048.6248400211334\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-df1a5c91b196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mval_pd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"similarity_rating_clipped\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_rating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_rating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "val_pd = val.compute()\n",
    "start = time.time()\n",
    "val_pd[\"similarity_rating\"] = val_pd.apply(\n",
    "    lambda row: row.dual_bayesian_avg + scorer.predict_pair(row.user_id, row.recipe_id),\n",
    "    axis=1\n",
    ")\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "433541d0-9a4d-40f3-9d37-d7795c2b4848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848890510543224"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "val_pd[\"similarity_rating_clipped\"] = val_pd.similarity_rating.clip(0, 5)\n",
    "mean_squared_error(val_pd.rating, val_pd.similarity_rating_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09e4736e-3919-44d4-b363-9cafc24de52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pd.to_csv('val_user_similarity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c500a-4c17-4b85-8571-06a198c314f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
