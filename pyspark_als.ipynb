{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48893349-e1ad-41be-b4fa-1b23b4d97e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !hdfs dfs -put data/sample_movie_ratings.txt /sample_movie_ratings.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4325126-f675-4097-ac2e-db2e27eac303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "lines = spark.read.option(\"header\", \"true\").csv(\"data/interactions_train.csv\").rdd\n",
    "ratingsRDD = lines.map(lambda p: Row(userId=int(p[0]), recipeId=int(p[1]),\n",
    "                                     rating=float(p[3])))\n",
    "ratings = spark.createDataFrame(ratingsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cf5b35f-bc71-4cef-866e-bd85954c9b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.574791656605009 0.958166372324364\n"
     ]
    }
   ],
   "source": [
    "(unnorm_training, unnorm_test) = ratings.randomSplit([0.8, 0.2])\n",
    "mean = unnorm_training.agg({'rating': 'mean'}).collect()[0][0]\n",
    "std = unnorm_training.agg({'rating': 'std'}).collect()[0][0]\n",
    "print(mean, std)\n",
    "training = unnorm_training.withColumn(\"rating\",(col(\"rating\") - mean) / std)\n",
    "test = unnorm_test.withColumn(\"rating\",(col(\"rating\") - mean) / std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4193d682-a26e-4a0c-91af-61d66e388c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.01 1.48371886416645\n",
      "+------+--------+------+-------------------+\n",
      "|userId|recipeId|rating|         prediction|\n",
      "+------+--------+------+-------------------+\n",
      "|  3794|    7508|   4.0| 10.241341926494322|\n",
      "|  3794|   32045|   5.0|  4.067638789116292|\n",
      "|  6357|     229|   4.0| 3.9965843885055836|\n",
      "|  6357|    3722|   4.0|   4.42073889735041|\n",
      "|  6357|    4174|   4.0| 4.7177544553732735|\n",
      "|  6357|    5287|   5.0|  4.733217532082325|\n",
      "|  6357|    8961|   0.0|-0.8306088962271225|\n",
      "|  6357|    9233|   5.0|  6.697984928999947|\n",
      "|  6357|   10392|   4.0|  4.731662295080575|\n",
      "|  6357|   10455|   5.0| 5.7782395226640695|\n",
      "|  6357|   11291|   4.0|    4.6651057272019|\n",
      "|  6357|   11455|   5.0|  5.382089574138453|\n",
      "|  6357|   11580|   5.0| 3.4035774470043627|\n",
      "|  6357|   11642|   5.0|  4.670250358169597|\n",
      "|  6357|   11644|   5.0|  4.497805618877775|\n",
      "|  6357|   11749|   5.0|   4.52909787271883|\n",
      "|  6357|   13366|   2.0| 3.7269355019082004|\n",
      "|  6357|   13868|   4.0|  4.849276431205299|\n",
      "|  6357|   14248|   5.0|  3.305638421766975|\n",
      "|  6357|   14470|   5.0|  5.228721020933418|\n",
      "+------+--------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "1 0.05 1.1509768204822701\n",
      "+------+--------+------+------------------+\n",
      "|userId|recipeId|rating|        prediction|\n",
      "+------+--------+------+------------------+\n",
      "|  3794|    7508|   4.0| 7.128844131707769|\n",
      "|  3794|   32045|   5.0|4.0804891441913655|\n",
      "|  6357|     229|   4.0|3.8331260055577268|\n",
      "|  6357|    3722|   4.0| 4.259076532081247|\n",
      "|  6357|    4174|   4.0| 4.769015267982243|\n",
      "|  6357|    5287|   5.0| 4.842882093697541|\n",
      "|  6357|    8961|   0.0|0.4369697837571751|\n",
      "|  6357|    9233|   5.0| 6.596894966497767|\n",
      "|  6357|   10392|   4.0| 4.814883115994833|\n",
      "|  6357|   10455|   5.0| 5.111576310039753|\n",
      "|  6357|   11291|   4.0| 4.685387544286187|\n",
      "|  6357|   11455|   5.0| 5.178410937909147|\n",
      "|  6357|   11580|   5.0| 3.715346218495272|\n",
      "|  6357|   11642|   5.0| 4.739304868515862|\n",
      "|  6357|   11644|   5.0|  4.51602508749842|\n",
      "|  6357|   11749|   5.0| 4.529287492499151|\n",
      "|  6357|   13366|   2.0|3.7606784351573186|\n",
      "|  6357|   13868|   4.0| 4.887981525245919|\n",
      "|  6357|   14248|   5.0|3.0609667610655826|\n",
      "|  6357|   14470|   5.0| 5.157016866584192|\n",
      "+------+--------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "1 0.1 1.080975220484848\n",
      "+------+--------+------+------------------+\n",
      "|userId|recipeId|rating|        prediction|\n",
      "+------+--------+------+------------------+\n",
      "|  3794|    7508|   4.0| 6.066660963832829|\n",
      "|  3794|   32045|   5.0| 4.137275861913972|\n",
      "|  6357|     229|   4.0|4.0779076052541665|\n",
      "|  6357|    3722|   4.0| 4.169555007416311|\n",
      "|  6357|    4174|   4.0| 4.766088235044765|\n",
      "|  6357|    5287|   5.0| 4.925389310589403|\n",
      "|  6357|    8961|   0.0| 1.323602135896595|\n",
      "|  6357|    9233|   5.0| 6.400985619103883|\n",
      "|  6357|   10392|   4.0| 4.824698440917035|\n",
      "|  6357|   10455|   5.0| 4.387275865927123|\n",
      "|  6357|   11291|   4.0| 4.697541257355245|\n",
      "|  6357|   11455|   5.0| 5.077216461972715|\n",
      "|  6357|   11580|   5.0|3.8883748909065003|\n",
      "|  6357|   11642|   5.0| 4.744106475541221|\n",
      "|  6357|   11644|   5.0| 4.537441546400549|\n",
      "|  6357|   11749|   5.0| 4.511299852380139|\n",
      "|  6357|   13366|   2.0|3.9777884183560417|\n",
      "|  6357|   13868|   4.0| 4.884259333540629|\n",
      "|  6357|   14248|   5.0|3.0799818096488907|\n",
      "|  6357|   14470|   5.0| 5.094354951855114|\n",
      "+------+--------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "1 0.5 0.9623993962922732\n",
      "+------+--------+------+------------------+\n",
      "|userId|recipeId|rating|        prediction|\n",
      "+------+--------+------+------------------+\n",
      "|  3794|    7508|   4.0| 4.597592770378895|\n",
      "|  3794|   32045|   5.0| 4.518462731282784|\n",
      "|  6357|     229|   4.0| 4.566675935004513|\n",
      "|  6357|    3722|   4.0| 4.350612724524895|\n",
      "|  6357|    4174|   4.0| 4.568582784040227|\n",
      "|  6357|    5287|   5.0| 4.892591909808855|\n",
      "|  6357|    8961|   0.0| 4.445315188581477|\n",
      "|  6357|    9233|   5.0| 4.650410660040001|\n",
      "|  6357|   10392|   4.0| 4.747284854721402|\n",
      "|  6357|   10455|   5.0| 4.561502633338992|\n",
      "|  6357|   11291|   4.0| 4.719785199945289|\n",
      "|  6357|   11455|   5.0|  4.58297069842637|\n",
      "|  6357|   11580|   5.0| 4.497709686396253|\n",
      "|  6357|   11642|   5.0| 4.611075968933103|\n",
      "|  6357|   11644|   5.0|4.6028378705963835|\n",
      "|  6357|   11749|   5.0|  4.50198493549669|\n",
      "|  6357|   13366|   2.0| 5.156198063793549|\n",
      "|  6357|   13868|   4.0| 4.720749793265597|\n",
      "|  6357|   14248|   5.0| 4.076241900979082|\n",
      "|  6357|   14470|   5.0| 4.676986363229494|\n",
      "+------+--------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "1 0.75 0.9531580324843619\n",
      "+------+--------+------+------------------+\n",
      "|userId|recipeId|rating|        prediction|\n",
      "+------+--------+------+------------------+\n",
      "|  3794|    7508|   4.0| 4.575013010980101|\n",
      "|  3794|   32045|   5.0| 4.562540952713129|\n",
      "|  6357|     229|   4.0| 4.577317500777491|\n",
      "|  6357|    3722|   4.0| 4.536303520746107|\n",
      "|  6357|    4174|   4.0| 4.573051688962642|\n",
      "|  6357|    5287|   5.0|4.6387925497659035|\n",
      "|  6357|    8961|   0.0| 4.575041353734899|\n",
      "|  6357|    9233|   5.0| 4.597223891140757|\n",
      "|  6357|   10392|   4.0| 4.619738390742053|\n",
      "|  6357|   10455|   5.0| 4.574097617507322|\n",
      "|  6357|   11291|   4.0| 4.661319970768565|\n",
      "|  6357|   11455|   5.0|  4.57562140639038|\n",
      "|  6357|   11580|   5.0| 4.555090710053837|\n",
      "|  6357|   11642|   5.0| 4.578417731109848|\n",
      "|  6357|   11644|   5.0| 4.581608390529317|\n",
      "|  6357|   11749|   5.0| 4.581219645975122|\n",
      "|  6357|   13366|   2.0| 4.765942044736936|\n",
      "|  6357|   13868|   4.0| 4.610899955888144|\n",
      "|  6357|   14248|   5.0| 4.500812443253412|\n",
      "|  6357|   14470|   5.0| 4.584611927889626|\n",
      "+------+--------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "1 1.0 0.951288077492901\n",
      "+------+--------+------+------------------+\n",
      "|userId|recipeId|rating|        prediction|\n",
      "+------+--------+------+------------------+\n",
      "|  3794|    7508|   4.0|   4.5747846328566|\n",
      "|  3794|   32045|   5.0| 4.572545661609001|\n",
      "|  6357|     229|   4.0|4.5748381593372764|\n",
      "|  6357|    3722|   4.0| 4.573869605358983|\n",
      "|  6357|    4174|   4.0| 4.574722098418404|\n",
      "|  6357|    5287|   5.0| 4.578565870782407|\n",
      "|  6357|    8961|   0.0| 4.574299021039038|\n",
      "|  6357|    9233|   5.0|  4.57733386558062|\n",
      "|  6357|   10392|   4.0| 4.580354679514904|\n",
      "|  6357|   10455|   5.0| 4.574814256473701|\n",
      "|  6357|   11291|   4.0| 4.595981368114578|\n",
      "|  6357|   11455|   5.0|  4.57496317446019|\n",
      "|  6357|   11580|   5.0| 4.572914503367935|\n",
      "|  6357|   11642|   5.0| 4.574414817581733|\n",
      "|  6357|   11644|   5.0| 4.574938675721906|\n",
      "|  6357|   11749|   5.0| 4.575407113526556|\n",
      "|  6357|   13366|   2.0| 4.597500139636671|\n",
      "|  6357|   13868|   4.0| 4.577996141611612|\n",
      "|  6357|   14248|   5.0| 4.571979866639054|\n",
      "|  6357|   14470|   5.0| 4.576070542489217|\n",
      "+------+--------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "1 2.0 0.9503730945661135\n",
      "+------+--------+------+------------------+\n",
      "|userId|recipeId|rating|        prediction|\n",
      "+------+--------+------+------------------+\n",
      "|  3794|    7508|   4.0| 4.574791687069769|\n",
      "|  3794|   32045|   5.0| 4.574791998995867|\n",
      "|  6357|     229|   4.0| 4.574791656991069|\n",
      "|  6357|    3722|   4.0| 4.574791639870618|\n",
      "|  6357|    4174|   4.0| 4.574791658468702|\n",
      "|  6357|    5287|   5.0| 4.574791440046993|\n",
      "|  6357|    8961|   0.0| 4.574791800393626|\n",
      "|  6357|    9233|   5.0| 4.574791714621772|\n",
      "|  6357|   10392|   4.0| 4.574791858074964|\n",
      "|  6357|   10455|   5.0| 4.574791663171183|\n",
      "|  6357|   11291|   4.0|4.5747914830436684|\n",
      "|  6357|   11455|   5.0| 4.574791633054884|\n",
      "|  6357|   11580|   5.0| 4.574791678590225|\n",
      "|  6357|   11642|   5.0| 4.574791642481781|\n",
      "|  6357|   11644|   5.0| 4.574791652261157|\n",
      "|  6357|   11749|   5.0|4.5747916395187165|\n",
      "|  6357|   13366|   2.0|4.5747912525983105|\n",
      "|  6357|   13868|   4.0|4.5747916254966405|\n",
      "|  6357|   14248|   5.0| 4.574791657657505|\n",
      "|  6357|   14470|   5.0| 4.574791622439657|\n",
      "+------+--------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "10 0.01 1.215239655132234\n",
      "10 0.05 1.0597232200220414\n",
      "10 0.1 1.0079133082764162\n",
      "10 0.5 0.9524855707801849\n",
      "10 0.75 0.9507269587707724\n",
      "10 1.0 0.9504453452535075\n",
      "10 2.0 0.9503696741925955\n",
      "+-------+--------+------+------------------+\n",
      "| userId|recipeId|rating|        prediction|\n",
      "+-------+--------+------+------------------+\n",
      "| 597538|     271|   5.0| 4.574791656678258|\n",
      "| 296050|     271|   5.0| 4.574791656640505|\n",
      "|  56463|     375|   5.0|  4.57479165633474|\n",
      "|   2625|     471|   3.0| 4.575296901022565|\n",
      "|  39835|     471|   5.0|4.5747917813680266|\n",
      "| 286566|     580|   4.0| 4.574791656617105|\n",
      "|1366128|     580|   4.0| 4.574791656593256|\n",
      "|  64683|     593|   4.0| 4.574791701607756|\n",
      "|  35526|     593|   5.0| 4.574792091367367|\n",
      "|  55785|     626|   5.0| 4.574791656610367|\n",
      "| 297913|     642|   3.0|  4.57479164472023|\n",
      "| 321820|     683|   3.0| 4.574791569915773|\n",
      "| 234222|     897|   5.0| 4.574791657227324|\n",
      "|  12875|     916|   5.0| 4.574792074332344|\n",
      "| 288693|     916|   5.0| 4.574791378203596|\n",
      "| 527515|     916|   5.0|  4.57479180148235|\n",
      "| 164913|     916|   5.0| 4.574791752925555|\n",
      "| 316717|     916|   3.0| 4.574791725647622|\n",
      "| 439210|     916|   5.0| 4.574791637610906|\n",
      "| 934824|     916|   5.0| 4.574792158670273|\n",
      "+-------+--------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "100 0.01 0.9625590457587642\n",
      "100 0.05 0.9486516259875147\n",
      "+-------+--------+------+------------------+\n",
      "| userId|recipeId|rating|        prediction|\n",
      "+-------+--------+------+------------------+\n",
      "| 296050|     271|   5.0| 4.674086907846423|\n",
      "| 597538|     271|   5.0| 4.690711611399372|\n",
      "|  56463|     375|   5.0| 4.512772142551794|\n",
      "|   2625|     471|   3.0| 4.745804390514075|\n",
      "|  39835|     471|   5.0| 4.464286961178553|\n",
      "| 286566|     580|   4.0| 4.504978916998814|\n",
      "|1366128|     580|   4.0| 4.699788724525418|\n",
      "|  64683|     593|   4.0| 4.242218058247011|\n",
      "|  35526|     593|   5.0| 4.732204379992906|\n",
      "|  55785|     626|   5.0| 4.851620758913445|\n",
      "| 297913|     642|   3.0| 4.312361992645233|\n",
      "| 321820|     683|   3.0| 4.700120097789839|\n",
      "| 234222|     897|   5.0|5.0153455083407295|\n",
      "|  12875|     916|   5.0| 4.656394289734509|\n",
      "| 164913|     916|   5.0| 5.027073114998335|\n",
      "| 384041|     916|   0.0| 4.301142960923155|\n",
      "| 527515|     916|   5.0| 4.671351004565724|\n",
      "| 173579|     916|   5.0| 5.082364291165723|\n",
      "| 178742|     916|   5.0|   3.6609124808225|\n",
      "| 316717|     916|   3.0| 4.968748479235147|\n",
      "+-------+--------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "100 0.1 0.9434189668312916\n",
      "+-------+--------+------+------------------+\n",
      "| userId|recipeId|rating|        prediction|\n",
      "+-------+--------+------+------------------+\n",
      "| 296050|     271|   5.0| 4.667476154713026|\n",
      "| 597538|     271|   5.0| 4.698556751002481|\n",
      "|  56463|     375|   5.0|  4.55686628193501|\n",
      "|   2625|     471|   3.0| 4.755382846874222|\n",
      "|  39835|     471|   5.0|4.4915591064849805|\n",
      "| 286566|     580|   4.0|  4.48804502073064|\n",
      "|1366128|     580|   4.0| 4.665327518416063|\n",
      "|  64683|     593|   4.0| 4.319334694933686|\n",
      "|  35526|     593|   5.0| 4.627666348675131|\n",
      "|  55785|     626|   5.0| 4.807558851644686|\n",
      "| 297913|     642|   3.0| 4.399294853754978|\n",
      "| 321820|     683|   3.0| 4.684117677504438|\n",
      "| 234222|     897|   5.0| 4.850291153851789|\n",
      "|  12875|     916|   5.0| 4.546118724307081|\n",
      "| 164913|     916|   5.0| 4.862769858012439|\n",
      "| 384041|     916|   0.0| 4.287240475387691|\n",
      "| 527515|     916|   5.0|4.5865594962945195|\n",
      "| 173579|     916|   5.0| 4.933425422793583|\n",
      "| 178742|     916|   5.0| 3.958924257473988|\n",
      "| 316717|     916|   3.0| 4.832353735864606|\n",
      "+-------+--------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "100 0.5 0.9504136001791693\n",
      "100 0.75 0.9503963850221308\n",
      "100 1.0 0.950387232465696\n",
      "100 2.0 0.9503717384947064\n",
      "200 0.01 0.950874641030281\n",
      "200 0.05 0.9430603490629885\n",
      "+-------+--------+------+------------------+\n",
      "| userId|recipeId|rating|        prediction|\n",
      "+-------+--------+------+------------------+\n",
      "| 296050|     271|   5.0| 4.741163722755231|\n",
      "| 597538|     271|   5.0|  4.73338686669028|\n",
      "|  56463|     375|   5.0| 4.515034333694518|\n",
      "|   2625|     471|   3.0| 4.689028966524597|\n",
      "|  39835|     471|   5.0| 4.503415184711084|\n",
      "| 286566|     580|   4.0| 4.468688083289424|\n",
      "|1366128|     580|   4.0| 4.610385023765921|\n",
      "|  64683|     593|   4.0| 4.818886665860694|\n",
      "|  35526|     593|   5.0| 4.879677019115909|\n",
      "|  55785|     626|   5.0|  4.86150410323466|\n",
      "| 297913|     642|   3.0| 4.500962010258945|\n",
      "| 321820|     683|   3.0| 4.501679062368003|\n",
      "| 234222|     897|   5.0| 4.601994836608732|\n",
      "|  12875|     916|   5.0| 4.322013151520026|\n",
      "| 164913|     916|   5.0| 4.848737216129072|\n",
      "| 384041|     916|   0.0| 4.426599759454151|\n",
      "| 527515|     916|   5.0|4.6219756885551835|\n",
      "| 173579|     916|   5.0| 4.920283743659426|\n",
      "| 178742|     916|   5.0|4.0260914436645034|\n",
      "| 316717|     916|   3.0| 4.491440722176224|\n",
      "+-------+--------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "200 0.1 0.9398560236792783\n",
      "+-------+--------+------+------------------+\n",
      "| userId|recipeId|rating|        prediction|\n",
      "+-------+--------+------+------------------+\n",
      "| 296050|     271|   5.0| 4.728342208819117|\n",
      "| 597538|     271|   5.0| 4.685941808154722|\n",
      "|  56463|     375|   5.0| 4.551989036524113|\n",
      "|   2625|     471|   3.0| 4.688177803119373|\n",
      "|  39835|     471|   5.0|4.5200262458341935|\n",
      "| 286566|     580|   4.0|4.4487672301925745|\n",
      "|1366128|     580|   4.0|4.6137584375788725|\n",
      "|  64683|     593|   4.0| 4.753987735304869|\n",
      "|  35526|     593|   5.0| 4.789453512550912|\n",
      "|  55785|     626|   5.0| 4.818407303286706|\n",
      "| 297913|     642|   3.0| 4.516841059716885|\n",
      "| 321820|     683|   3.0| 4.518670044816301|\n",
      "| 234222|     897|   5.0| 4.604546956156413|\n",
      "|  12875|     916|   5.0| 4.222548487142802|\n",
      "| 164913|     916|   5.0| 4.763351111012887|\n",
      "| 384041|     916|   0.0|  4.32525381042701|\n",
      "| 527515|     916|   5.0| 4.497846981639937|\n",
      "| 173579|     916|   5.0|4.8767865087692535|\n",
      "| 178742|     916|   5.0| 4.236937388481287|\n",
      "| 316717|     916|   3.0| 4.508597137825931|\n",
      "+-------+--------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "200 0.5 0.9499006360584399\n",
      "200 0.75 0.9502825589833466\n",
      "200 1.0 0.9503521904321499\n",
      "200 2.0 0.9503721527016511\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3444.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4351.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4351.0 (TID 8955) (aidans-air.lan executor driver): java.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.apache.spark.ml.recommendation.ALS$CholeskySolver.solve(ALS.scala:792)\n\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$computeFactors$4(ALS.scala:1766)\n\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$3818/281597203.apply(Unknown Source)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:751)\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$3640/2119548997.apply(Unknown Source)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:156)\n\tat org.apache.spark.rdd.CoGroupedRDD.$anonfun$compute$4(CoGroupedRDD.scala:155)\n\tat org.apache.spark.rdd.CoGroupedRDD.$anonfun$compute$4$adapted(CoGroupedRDD.scala:154)\n\tat org.apache.spark.rdd.CoGroupedRDD$$Lambda$3766/635422166.apply(Unknown Source)\n\tat scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)\n\tat scala.collection.TraversableLike$WithFilter$$Lambda$133/7967307.apply(Unknown Source)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)\n\tat org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:154)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1253)\n\tat org.apache.spark.ml.recommendation.ALS$.train(ALS.scala:1075)\n\tat org.apache.spark.ml.recommendation.ALS.$anonfun$fit$1(ALS.scala:722)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:704)\n\tat org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:606)\n\tat sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.apache.spark.ml.recommendation.ALS$CholeskySolver.solve(ALS.scala:792)\n\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$computeFactors$4(ALS.scala:1766)\n\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$3818/281597203.apply(Unknown Source)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:751)\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$3640/2119548997.apply(Unknown Source)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:156)\n\tat org.apache.spark.rdd.CoGroupedRDD.$anonfun$compute$4(CoGroupedRDD.scala:155)\n\tat org.apache.spark.rdd.CoGroupedRDD.$anonfun$compute$4$adapted(CoGroupedRDD.scala:154)\n\tat org.apache.spark.rdd.CoGroupedRDD$$Lambda$3766/635422166.apply(Unknown Source)\n\tat scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)\n\tat scala.collection.TraversableLike$WithFilter$$Lambda$133/7967307.apply(Unknown Source)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)\n\tat org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:154)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aee963b7a97d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         als = ALS(rank=rank, maxIter=10, regParam=reg, userCol=\"userId\", itemCol=\"recipeId\", ratingCol=\"rating\",\n\u001b[1;32m      8\u001b[0m                   coldStartStrategy=\"drop\")\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Evaluate the model by computing the RMSE on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise TypeError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o3444.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4351.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4351.0 (TID 8955) (aidans-air.lan executor driver): java.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.apache.spark.ml.recommendation.ALS$CholeskySolver.solve(ALS.scala:792)\n\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$computeFactors$4(ALS.scala:1766)\n\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$3818/281597203.apply(Unknown Source)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:751)\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$3640/2119548997.apply(Unknown Source)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:156)\n\tat org.apache.spark.rdd.CoGroupedRDD.$anonfun$compute$4(CoGroupedRDD.scala:155)\n\tat org.apache.spark.rdd.CoGroupedRDD.$anonfun$compute$4$adapted(CoGroupedRDD.scala:154)\n\tat org.apache.spark.rdd.CoGroupedRDD$$Lambda$3766/635422166.apply(Unknown Source)\n\tat scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)\n\tat scala.collection.TraversableLike$WithFilter$$Lambda$133/7967307.apply(Unknown Source)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)\n\tat org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:154)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1253)\n\tat org.apache.spark.ml.recommendation.ALS$.train(ALS.scala:1075)\n\tat org.apache.spark.ml.recommendation.ALS.$anonfun$fit$1(ALS.scala:722)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:704)\n\tat org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:606)\n\tat sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.apache.spark.ml.recommendation.ALS$CholeskySolver.solve(ALS.scala:792)\n\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$computeFactors$4(ALS.scala:1766)\n\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$3818/281597203.apply(Unknown Source)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:751)\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$3640/2119548997.apply(Unknown Source)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:156)\n\tat org.apache.spark.rdd.CoGroupedRDD.$anonfun$compute$4(CoGroupedRDD.scala:155)\n\tat org.apache.spark.rdd.CoGroupedRDD.$anonfun$compute$4$adapted(CoGroupedRDD.scala:154)\n\tat org.apache.spark.rdd.CoGroupedRDD$$Lambda$3766/635422166.apply(Unknown Source)\n\tat scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)\n\tat scala.collection.TraversableLike$WithFilter$$Lambda$133/7967307.apply(Unknown Source)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)\n\tat org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:154)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_rmse = 100\n",
    "for alpha in [0.01, 0.05, 0.1, 0.5, 1, 2]:\n",
    "    for reg in [0.05, 0.1]:\n",
    "        # Build the recommendation model using ALS on the training data\n",
    "        # Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "        als = ALS(rank=200, alpha=alpha, maxIter=10, regParam=reg, userCol=\"userId\", itemCol=\"recipeId\", ratingCol=\"rating\",\n",
    "                  coldStartStrategy=\"drop\")\n",
    "        model = als.fit(training)\n",
    "\n",
    "        # Evaluate the model by computing the RMSE on the test data\n",
    "        normalized_predictions = model.transform(test)\n",
    "        predictions = normalized_predictions.withColumn(\n",
    "            \"rating\",col(\"rating\") * std + mean\n",
    "        ).withColumn(\n",
    "            \"prediction\",col(\"prediction\") * std + mean\n",
    "        )\n",
    "        evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                        predictionCol=\"prediction\")\n",
    "\n",
    "        rmse = evaluator.evaluate(predictions)\n",
    "        print(alpha, reg, rmse)\n",
    "        if rmse < best_rmse:\n",
    "            #print(f\"Best model -> rank:{rank}, reg:{reg}, rmse:{rmse}\")\n",
    "            predictions.show()\n",
    "            best_model = model\n",
    "            best_rmse = rmse\n",
    "\n",
    "        # Generate top 10 movie recommendations for each user\n",
    "        #userRecs = model.recommendForAllUsers(10)\n",
    "        # Generate top 10 user recommendations for each movie\n",
    "        #recipeRecs = model.recommendForAllItems(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b972a84-2a46-40c8-b5f2-eeba19521499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 53607)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aidankeogh/opt/anaconda3/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Users/aidankeogh/opt/anaconda3/lib/python3.8/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Users/aidankeogh/opt/anaconda3/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Users/aidankeogh/opt/anaconda3/lib/python3.8/socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/aidankeogh/opt/anaconda3/lib/python3.8/site-packages/pyspark/accumulators.py\", line 262, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/Users/aidankeogh/opt/anaconda3/lib/python3.8/site-packages/pyspark/accumulators.py\", line 235, in poll\n",
      "    if func():\n",
      "  File \"/Users/aidankeogh/opt/anaconda3/lib/python3.8/site-packages/pyspark/accumulators.py\", line 239, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/Users/aidankeogh/opt/anaconda3/lib/python3.8/site-packages/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_model.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5876ad-da9a-46cf-97fd-75f5d0f39127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bba6f8-3fd7-46f2-81af-32cfe9ac9db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
